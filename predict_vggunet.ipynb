{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0611 22:05:34.276548 11092 deprecation_wrapper.py:119] From D:\\anaconda_64anzhuang\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0611 22:05:34.301534 11092 deprecation_wrapper.py:119] From D:\\anaconda_64anzhuang\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0611 22:05:34.304514 11092 deprecation_wrapper.py:119] From D:\\anaconda_64anzhuang\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0611 22:05:34.342515 11092 deprecation_wrapper.py:119] From D:\\anaconda_64anzhuang\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "load train images...\n",
      "------------------------------\n",
      "------------------------------\n",
      "load test images...\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0611 22:05:34.636336 11092 deprecation_wrapper.py:119] From D:\\anaconda_64anzhuang\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0611 22:05:34.637324 11092 deprecation_wrapper.py:119] From D:\\anaconda_64anzhuang\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0611 22:05:35.001113 11092 deprecation_wrapper.py:119] From D:\\anaconda_64anzhuang\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0611 22:05:35.104681 11092 deprecation_wrapper.py:119] From D:\\anaconda_64anzhuang\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "W0611 22:05:36.267664 11092 deprecation_wrapper.py:119] From D:\\anaconda_64anzhuang\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0611 22:05:36.281655 11092 deprecation.py:323] From D:\\anaconda_64anzhuang\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 7s 4s/step\n"
     ]
    }
   ],
   "source": [
    "# %load predict.py\n",
    "from keras.preprocessing.image import img_to_array,load_img,array_to_img\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.callbacks import TensorBoard,ModelCheckpoint\n",
    "from keras.optimizers import Adam,SGD\n",
    "import glob\n",
    "\n",
    "class dataProcess(object):\n",
    "    def __init__(self, out_rows, out_cols, data_path=\"./orig_data/image\", label_path=\"./orig_data/mask\",\n",
    "                 test_path=\"./orig_data/test\", npy_path=\"./npy_data\", img_type=\"png\"):\n",
    "        # 数据处理类，初始化\n",
    "        self.out_rows = out_rows\n",
    "        self.out_cols = out_cols\n",
    "        self.data_path = data_path\n",
    "        self.label_path = label_path\n",
    "        self.img_type = img_type\n",
    "        self.test_path = test_path\n",
    "        self.npy_path = npy_path\n",
    "\n",
    "    # 创建训练数据\n",
    "    def create_train_data(self):\n",
    "        i = 0\n",
    "        print('-' * 30)\n",
    "        print('Creating training images...')\n",
    "        print('-' * 30)\n",
    "        imgs = glob.glob(self.data_path + \"/*.\" + self.img_type)\n",
    "        img_len=len(imgs)\n",
    "        print(len(imgs))\n",
    "\n",
    "\t\t# 此处有改动，1变为3\n",
    "        imgdatas = np.ndarray((len(imgs), self.out_rows, self.out_cols, 3), dtype=np.uint8)\n",
    "        imglabels = np.ndarray((len(imgs), self.out_rows, self.out_cols, 1), dtype=np.uint8)\n",
    "        for imgname in imgs:\n",
    "            midname = imgname[imgname.rindex(\"\\\\\") + 1:]\n",
    "            img = load_img(self.data_path + \"/\" + midname, color_mode='rgb')\n",
    "            label = load_img(self.label_path + \"/\" + midname, grayscale=True)\n",
    "            img = img_to_array(img)\n",
    "            label = img_to_array(label)\n",
    "            # img = cv2.imread(self.data_path + \"/\" + midname,cv2.IMREAD_GRAYSCALE)\n",
    "            # label = cv2.imread(self.label_path + \"/\" + midname,cv2.IMREAD_GRAYSCALE)\n",
    "            # img = np.array([img])\n",
    "            # label = np.array([label])\n",
    "            imgdatas[i] = img\n",
    "            imglabels[i] = label\n",
    "            if i % 100 == 0:\n",
    "                print('Done: {0}/{1} images'.format(i, len(imgs)))\n",
    "            i += 1\n",
    "        print('loading done')\n",
    "        np.save(self.npy_path + '/imgs_train.npy', imgdatas)\n",
    "        np.save(self.npy_path + '/imgs_mask_train.npy', imglabels)\n",
    "        print('Saving to .npy files done.')\n",
    "\n",
    "    # 创建测试数据\n",
    "    def create_test_data(self):\n",
    "        i = 0\n",
    "        print('-' * 30)\n",
    "        print('Creating test images...')\n",
    "        print('-' * 30)\n",
    "        imgs = glob.glob(self.test_path + \"/*.\" + self.img_type)\n",
    "        print(len(imgs))\n",
    "        imgdatas = np.ndarray((len(imgs), self.out_rows, self.out_cols, 3), dtype=np.uint8)\n",
    "        for imgname in imgs:\n",
    "            midname = imgname[imgname.rindex(\"\\\\\") + 1:]\n",
    "            img = load_img(self.test_path + \"/\" + midname, color_mode='rgb')\n",
    "            img = img_to_array(img)\n",
    "            # img = cv2.imread(self.test_path + \"/\" + midname,cv2.IMREAD_GRAYSCALE)\n",
    "            # img = np.array([img])\n",
    "            imgdatas[i] = img\n",
    "            i += 1\n",
    "        print('loading done')\n",
    "        np.save(self.npy_path + '/imgs_test.npy', imgdatas)\n",
    "        print('Saving to imgs_test.npy files done.')\n",
    "\n",
    "    # 加载训练图片与mask\n",
    "    def load_train_data(self):\n",
    "        print('-' * 30)\n",
    "        print('load train images...')\n",
    "        print('-' * 30)\n",
    "        imgs_train = np.load(self.npy_path + \"/imgs_train.npy\")\n",
    "        imgs_mask_train = np.load(self.npy_path + \"/imgs_mask_train.npy\")\n",
    "        imgs_train = imgs_train.astype('float32')\n",
    "        imgs_mask_train = imgs_mask_train.astype('float32')\n",
    "        imgs_train /= 255\n",
    "        # mean = imgs_train.mean(axis=0)\n",
    "        # imgs_train -= mean\n",
    "        imgs_mask_train /= 255\n",
    "        # 做一个阈值处理，输出的概率值大于0.5的就认为是对象，否则认为是背景\n",
    "        imgs_mask_train[imgs_mask_train > 0.5] = 1\n",
    "        imgs_mask_train[imgs_mask_train <= 0.5] = 0\n",
    "        return imgs_train, imgs_mask_train\n",
    "\n",
    "    # 加载测试图片\n",
    "    def load_test_data(self):\n",
    "        print('-' * 30)\n",
    "        print('load test images...')\n",
    "        print('-' * 30)\n",
    "        imgs_test = np.load(self.npy_path + \"/imgs_test.npy\")\n",
    "        imgs_test = imgs_test.astype('float32')\n",
    "        imgs_test /= 255\n",
    "        # mean = imgs_test.mean(axis=0)\n",
    "        # imgs_test -= mean\n",
    "        return imgs_test\n",
    "\n",
    "IMAGE_ORDERING = 'channels_last'\n",
    "def VGG16(n_classes,importModel = None):\n",
    "\n",
    "    image_input = Input(shape = (512,512,3))\n",
    "    #block1\n",
    "    x = Conv2D(64,(3,3),activation = 'relu',padding = 'same',name = 'block1_conv1')(image_input)\n",
    "    x = Conv2D(64,(3,3),activation = 'relu',padding = 'same', name = 'block1_conv2')(x)\n",
    "    f1 = x\n",
    "\n",
    "    x = MaxPooling2D((2,2), strides = (2,2), name = 'block1_pool')(x)\n",
    "    x = Conv2D(128,(3,3),activation = 'relu',padding = 'same',name = 'block2_conv1')(x)\n",
    "    x = Conv2D(128,(3,3),activation = 'relu',padding = 'same',name = 'block2_conv2')(x)\n",
    "    f2 = x\n",
    "\n",
    "    x = MaxPooling2D((2,2),strides = (2,2),name = 'block2_pool')(x)\n",
    "    x = Conv2D(256,(3,3),activation = 'relu',padding = 'same',name = 'block3_conv1')(x)\n",
    "    x = Conv2D(256,(3,3),activation = 'relu',padding = 'same',name = 'block3_conv2')(x)\n",
    "    x = Conv2D(256,(3,3),activation = 'relu',padding = 'same',name = 'block3_conv3')(x)\n",
    "    f3 = x\n",
    "\n",
    "    x = MaxPooling2D((2,2),strides = (2,2),name = 'block3_pool')(x)\n",
    "    x = Conv2D(512,(3,3),activation = 'relu',padding = 'same', name = 'block4_conv1')(x)\n",
    "    x = Conv2D(512,(3,3),activation = 'relu',padding = 'same', name = 'block4_conv2')(x)\n",
    "    x = Conv2D(512,(3,3),activation = 'relu',padding = 'same', name = 'block4_conv3')(x)\n",
    "    f4 = x\n",
    "\n",
    "    x = MaxPooling2D((2,2),strides = (2,2),name = 'block4_pool')(x)\n",
    "    x = Conv2D(512,(3,3),activation = 'relu',padding = 'same', name = 'block5_conv1')(x)\n",
    "    x = Conv2D(512,(3,3),activation = 'relu',padding = 'same', name = 'block5_conv2')(x)\n",
    "    x = Conv2D(512,(3,3),activation = 'relu',padding = 'same', name = 'block5_conv3')(x)\n",
    "    f5 = x\n",
    "\n",
    "    x = MaxPooling2D((2,2),strides = (2,2),name = 'block5_pool')(x)\n",
    "\n",
    "\n",
    "    # x = Flatten(name='flatten')(x)\n",
    "    # x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "    # x = Dense(4096, activation='relu+', name='fc2')(x)\n",
    "    # x = Dense(1000, activation='softmax', name='predictions')(x)\n",
    "    vgg = Model(image_input, x, name='vgg16')\n",
    "    # vgg.load_weights(\"C:/Users/hq/.keras/models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\")\n",
    "\n",
    "    levels = [f1, f2, f3, f4, f5]\n",
    "\n",
    "    o = f5\n",
    "    o = (ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING))(o)\n",
    "    o = (Conv2D(512, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n",
    "    o = (BatchNormalization())(o)\n",
    "\n",
    "    o = (UpSampling2D((2, 2), data_format=IMAGE_ORDERING))(o)\n",
    "    o = (concatenate([o, f4], axis=3))\n",
    "    o = (ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING))(o)\n",
    "    o = (Conv2D(256, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n",
    "    o = (BatchNormalization())(o)\n",
    "\n",
    "    o = (UpSampling2D((2, 2), data_format=IMAGE_ORDERING))(o)\n",
    "    o = (concatenate([o, f3], axis=3))\n",
    "    o = (ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING))(o)\n",
    "    o = (Conv2D(128, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n",
    "    o = (BatchNormalization())(o)\n",
    "\n",
    "    o = (UpSampling2D((2, 2), data_format=IMAGE_ORDERING))(o)\n",
    "    o = (concatenate([o, f2], axis=3))\n",
    "    o = (ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING))(o)\n",
    "    o = (Conv2D(64, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n",
    "    o = (BatchNormalization())(o)\n",
    "\n",
    "    o = (UpSampling2D((2, 2), data_format=IMAGE_ORDERING))(o)\n",
    "    o = (concatenate([o, f1], axis=3))\n",
    "    o = (ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING))(o)\n",
    "    o = (Conv2D(32, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n",
    "    o = (BatchNormalization())(o)\n",
    "\n",
    "    o = Conv2D(n_classes, (3, 3), padding='same', data_format=IMAGE_ORDERING)(o)\n",
    "    o= Conv2D(1, 1, activation='sigmoid')(o)\n",
    "\n",
    "    # conv10 = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
    "    # o_shape = Model(image_input, o).output_shape\n",
    "\t#\n",
    "    # output_height = o_shape[1]\n",
    "    # output_width = o_shape[2]\n",
    "\t#\n",
    "    # o = (Reshape((n_classes, output_height * output_width)))(o)\n",
    "\t#\n",
    "    # o = (Permute((2, 1)))(o)\n",
    "    # o = (Activation('softmax'))(o)\n",
    "    model = Model(image_input, o)\n",
    "\n",
    "    # model.outputWidth = output_width\n",
    "    # model.outputHeight = output_height\n",
    "\n",
    "    return model\n",
    "\n",
    "    #Classification block\n",
    "    # x = Flatten(name = 'flatten')(x)\n",
    "    # x = Dense(4096,activation = 'relu',name = 'fc1')(x)\n",
    "    # x = Dense(4096,activation = 'relu',name = 'fc2')(x)\n",
    "    # x = Dense(num_classes,activation = 'softmax',name = 'fc3')(x)\n",
    "\n",
    "    # if importModel:\n",
    "    #     model = Sequential()\n",
    "    #     model.load_weights(importModel)\n",
    "    # return model\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    mydata = dataProcess(512, 512)\n",
    "    imgs_train, imgs_mask_train = mydata.load_train_data()\n",
    "    imgs_test = mydata.load_test_data()\n",
    "    return imgs_train, imgs_mask_train, imgs_test\n",
    "\n",
    "# 将预测生成的numpy数组转换为灰度图\n",
    "def save_img_gray():\n",
    "    print(\"array to image\")\n",
    "    imgs = np.load('./results/pred_imgs_mask_test.npy')\n",
    "    for i in range(imgs.shape[0]):\n",
    "        img = imgs[i]\n",
    "        img = array_to_img(img)\n",
    "        img.save(\"./results/%d.jpg\" % (i))\n",
    "\n",
    "# 将预测生成的numpy数组转换为二值图\n",
    "def save_img_binary():\n",
    "    print(\"array to image\")\n",
    "    imgs = np.load('./results/imgs_mask_test.npy')\n",
    "    imgs[imgs > 0.5] = 1\n",
    "    imgs[imgs <= 0.5] = 0\n",
    "    for i in range(imgs.shape[0]):\n",
    "        img = imgs[i]\n",
    "        img = array_to_img(img)\n",
    "        img.save(\"./results/%d_binary.png\" % (i + 1))\n",
    "if __name__ == \"__main__\":\n",
    "    imgs_train, imgs_mask_train, imgs_test=load_data()\n",
    "    model = VGG16(2,'vgg16_weights.h5')\n",
    "    model.load_weights('my_VGG_unet.hdf5')\n",
    "    model.compile(optimizer=Adam(lr = 1e-4), \n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    imgs_mask_test = model.predict(imgs_test, batch_size=1, verbose=1)\n",
    "    np.save('./results_vggunet//pred_imgs_mask_test.npy', imgs_mask_test)\n",
    "    save_img_gray()\n",
    "\n",
    "\n",
    "    # model = VGG16(2, 'vgg16_weights.h5')\n",
    "    # print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
