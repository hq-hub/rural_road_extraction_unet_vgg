{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "load train images...\n",
      "------------------------------\n",
      "------------------------------\n",
      "load test images...\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda_64anzhuang\\lib\\site-packages\\ipykernel_launcher.py:203: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1 samples, validate on 1 samples\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 25s 25s/step - loss: 0.7671 - acc: 0.5234 - val_loss: 0.9030 - val_acc: 0.2855\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.76710, saving model to my_VGG_unet.hdf5\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.7005 - acc: 0.5669 - val_loss: 0.8588 - val_acc: 0.2862\n",
      "\n",
      "Epoch 00002: loss improved from 0.76710 to 0.70050, saving model to my_VGG_unet.hdf5\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 23s 23s/step - loss: 0.6684 - acc: 0.6087 - val_loss: 0.8492 - val_acc: 0.3575\n",
      "\n",
      "Epoch 00003: loss improved from 0.70050 to 0.66842, saving model to my_VGG_unet.hdf5\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 25s 25s/step - loss: 0.6494 - acc: 0.6566 - val_loss: 0.8539 - val_acc: 0.4229\n",
      "\n",
      "Epoch 00004: loss improved from 0.66842 to 0.64936, saving model to my_VGG_unet.hdf5\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 23s 23s/step - loss: 0.6377 - acc: 0.6827 - val_loss: 0.8056 - val_acc: 0.4851\n",
      "\n",
      "Epoch 00005: loss improved from 0.64936 to 0.63772, saving model to my_VGG_unet.hdf5\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 23s 23s/step - loss: 0.6274 - acc: 0.7028 - val_loss: 0.6906 - val_acc: 0.6166\n",
      "\n",
      "Epoch 00006: loss improved from 0.63772 to 0.62739, saving model to my_VGG_unet.hdf5\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 23s 23s/step - loss: 0.6169 - acc: 0.7197 - val_loss: 0.6118 - val_acc: 0.7161\n",
      "\n",
      "Epoch 00007: loss improved from 0.62739 to 0.61692, saving model to my_VGG_unet.hdf5\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.6063 - acc: 0.7379 - val_loss: 0.5625 - val_acc: 0.7698\n",
      "\n",
      "Epoch 00008: loss improved from 0.61692 to 0.60630, saving model to my_VGG_unet.hdf5\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 25s 25s/step - loss: 0.5955 - acc: 0.7576 - val_loss: 0.4422 - val_acc: 0.8739\n",
      "\n",
      "Epoch 00009: loss improved from 0.60630 to 0.59551, saving model to my_VGG_unet.hdf5\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 24s 24s/step - loss: 0.5854 - acc: 0.7721 - val_loss: 0.5382 - val_acc: 0.7886\n",
      "\n",
      "Epoch 00010: loss improved from 0.59551 to 0.58536, saving model to my_VGG_unet.hdf5\n"
     ]
    }
   ],
   "source": [
    "# %load transfer_learning.py\n",
    "from keras.preprocessing.image import img_to_array,load_img\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.callbacks import TensorBoard,ModelCheckpoint\n",
    "from keras.optimizers import Adam,SGD\n",
    "import glob\n",
    "\n",
    "class dataProcess(object):\n",
    "    def __init__(self, out_rows, out_cols, data_path=\"./orig_data/image\", label_path=\"./orig_data/mask\",\n",
    "                 test_path=\"./orig_data/test\", npy_path=\"./npy_data\", img_type=\"png\"):\n",
    "        # 数据处理类，初始化\n",
    "        self.out_rows = out_rows\n",
    "        self.out_cols = out_cols\n",
    "        self.data_path = data_path\n",
    "        self.label_path = label_path\n",
    "        self.img_type = img_type\n",
    "        self.test_path = test_path\n",
    "        self.npy_path = npy_path\n",
    "\n",
    "    # 创建训练数据\n",
    "    def create_train_data(self):\n",
    "        i = 0\n",
    "        print('-' * 30)\n",
    "        print('Creating training images...')\n",
    "        print('-' * 30)\n",
    "        imgs = glob.glob(self.data_path + \"/*.\" + self.img_type)\n",
    "        img_len=len(imgs)\n",
    "        print(len(imgs))\n",
    "\n",
    "\t\t# 此处有改动，1变为3\n",
    "        imgdatas = np.ndarray((len(imgs), self.out_rows, self.out_cols, 3), dtype=np.uint8)\n",
    "        imglabels = np.ndarray((len(imgs), self.out_rows, self.out_cols, 1), dtype=np.uint8)\n",
    "        for imgname in imgs:\n",
    "            midname = imgname[imgname.rindex(\"\\\\\") + 1:]\n",
    "            img = load_img(self.data_path + \"/\" + midname, color_mode='rgb')\n",
    "            label = load_img(self.label_path + \"/\" + midname, grayscale=True)\n",
    "            img = img_to_array(img)\n",
    "            label = img_to_array(label)\n",
    "            # img = cv2.imread(self.data_path + \"/\" + midname,cv2.IMREAD_GRAYSCALE)\n",
    "            # label = cv2.imread(self.label_path + \"/\" + midname,cv2.IMREAD_GRAYSCALE)\n",
    "            # img = np.array([img])\n",
    "            # label = np.array([label])\n",
    "            imgdatas[i] = img\n",
    "            imglabels[i] = label\n",
    "            if i % 100 == 0:\n",
    "                print('Done: {0}/{1} images'.format(i, len(imgs)))\n",
    "            i += 1\n",
    "        print('loading done')\n",
    "        np.save(self.npy_path + '/imgs_train.npy', imgdatas)\n",
    "        np.save(self.npy_path + '/imgs_mask_train.npy', imglabels)\n",
    "        print('Saving to .npy files done.')\n",
    "\n",
    "    # 创建测试数据\n",
    "    def create_test_data(self):\n",
    "        i = 0\n",
    "        print('-' * 30)\n",
    "        print('Creating test images...')\n",
    "        print('-' * 30)\n",
    "        imgs = glob.glob(self.test_path + \"/*.\" + self.img_type)\n",
    "        print(len(imgs))\n",
    "        imgdatas = np.ndarray((len(imgs), self.out_rows, self.out_cols, 3), dtype=np.uint8)\n",
    "        for imgname in imgs:\n",
    "            midname = imgname[imgname.rindex(\"\\\\\") + 1:]\n",
    "            img = load_img(self.test_path + \"/\" + midname, color_mode='rgb')\n",
    "            img = img_to_array(img)\n",
    "            # img = cv2.imread(self.test_path + \"/\" + midname,cv2.IMREAD_GRAYSCALE)\n",
    "            # img = np.array([img])\n",
    "            imgdatas[i] = img\n",
    "            i += 1\n",
    "        print('loading done')\n",
    "        np.save(self.npy_path + '/imgs_test.npy', imgdatas)\n",
    "        print('Saving to imgs_test.npy files done.')\n",
    "\n",
    "    # 加载训练图片与mask\n",
    "    def load_train_data(self):\n",
    "        print('-' * 30)\n",
    "        print('load train images...')\n",
    "        print('-' * 30)\n",
    "        imgs_train = np.load(self.npy_path + \"/imgs_train.npy\")\n",
    "        imgs_mask_train = np.load(self.npy_path + \"/imgs_mask_train.npy\")\n",
    "        imgs_train = imgs_train.astype('float32')\n",
    "        imgs_mask_train = imgs_mask_train.astype('float32')\n",
    "        imgs_train /= 255\n",
    "        # mean = imgs_train.mean(axis=0)\n",
    "        # imgs_train -= mean\n",
    "        imgs_mask_train /= 255\n",
    "        # 做一个阈值处理，输出的概率值大于0.5的就认为是对象，否则认为是背景\n",
    "        imgs_mask_train[imgs_mask_train > 0.5] = 1\n",
    "        imgs_mask_train[imgs_mask_train <= 0.5] = 0\n",
    "        return imgs_train, imgs_mask_train\n",
    "\n",
    "    # 加载测试图片\n",
    "    def load_test_data(self):\n",
    "        print('-' * 30)\n",
    "        print('load test images...')\n",
    "        print('-' * 30)\n",
    "        imgs_test = np.load(self.npy_path + \"/imgs_test.npy\")\n",
    "        imgs_test = imgs_test.astype('float32')\n",
    "        imgs_test /= 255\n",
    "        # mean = imgs_test.mean(axis=0)\n",
    "        # imgs_test -= mean\n",
    "        return imgs_test\n",
    "\n",
    "IMAGE_ORDERING = 'channels_last'\n",
    "def VGG16(n_classes,importModel = None):\n",
    "\n",
    "    image_input = Input(shape = (512,512,3))\n",
    "    #block1\n",
    "    x = Conv2D(64,(3,3),activation = 'relu',padding = 'same',name = 'block1_conv1')(image_input)\n",
    "    x = Conv2D(64,(3,3),activation = 'relu',padding = 'same', name = 'block1_conv2')(x)\n",
    "    f1 = x\n",
    "\n",
    "    x = MaxPooling2D((2,2), strides = (2,2), name = 'block1_pool')(x)\n",
    "    x = Conv2D(128,(3,3),activation = 'relu',padding = 'same',name = 'block2_conv1')(x)\n",
    "    x = Conv2D(128,(3,3),activation = 'relu',padding = 'same',name = 'block2_conv2')(x)\n",
    "    f2 = x\n",
    "\n",
    "    x = MaxPooling2D((2,2),strides = (2,2),name = 'block2_pool')(x)\n",
    "    x = Conv2D(256,(3,3),activation = 'relu',padding = 'same',name = 'block3_conv1')(x)\n",
    "    x = Conv2D(256,(3,3),activation = 'relu',padding = 'same',name = 'block3_conv2')(x)\n",
    "    x = Conv2D(256,(3,3),activation = 'relu',padding = 'same',name = 'block3_conv3')(x)\n",
    "    f3 = x\n",
    "\n",
    "    x = MaxPooling2D((2,2),strides = (2,2),name = 'block3_pool')(x)\n",
    "    x = Conv2D(512,(3,3),activation = 'relu',padding = 'same', name = 'block4_conv1')(x)\n",
    "    x = Conv2D(512,(3,3),activation = 'relu',padding = 'same', name = 'block4_conv2')(x)\n",
    "    x = Conv2D(512,(3,3),activation = 'relu',padding = 'same', name = 'block4_conv3')(x)\n",
    "    f4 = x\n",
    "\n",
    "    x = MaxPooling2D((2,2),strides = (2,2),name = 'block4_pool')(x)\n",
    "    x = Conv2D(512,(3,3),activation = 'relu',padding = 'same', name = 'block5_conv1')(x)\n",
    "    x = Conv2D(512,(3,3),activation = 'relu',padding = 'same', name = 'block5_conv2')(x)\n",
    "    x = Conv2D(512,(3,3),activation = 'relu',padding = 'same', name = 'block5_conv3')(x)\n",
    "    f5 = x\n",
    "\n",
    "    x = MaxPooling2D((2,2),strides = (2,2),name = 'block5_pool')(x)\n",
    "\n",
    "\n",
    "    # x = Flatten(name='flatten')(x)\n",
    "    # x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "    # x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "    # x = Dense(1000, activation='softmax', name='predictions')(x)\n",
    "    vgg = Model(image_input, x, name='vgg16')\n",
    "    vgg.load_weights(\"./vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\")\n",
    "\n",
    "    levels = [f1, f2, f3, f4, f5]\n",
    "\n",
    "    o = f5\n",
    "    o = (ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING))(o)\n",
    "    o = (Conv2D(512, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n",
    "    o = (BatchNormalization())(o)\n",
    "\n",
    "    o = (UpSampling2D((2, 2), data_format=IMAGE_ORDERING))(o)\n",
    "    o = (concatenate([o, f4], axis=3))\n",
    "    o = (ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING))(o)\n",
    "    o = (Conv2D(256, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n",
    "    o = (BatchNormalization())(o)\n",
    "\n",
    "    o = (UpSampling2D((2, 2), data_format=IMAGE_ORDERING))(o)\n",
    "    o = (concatenate([o, f3], axis=3))\n",
    "    o = (ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING))(o)\n",
    "    o = (Conv2D(128, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n",
    "    o = (BatchNormalization())(o)\n",
    "\n",
    "    o = (UpSampling2D((2, 2), data_format=IMAGE_ORDERING))(o)\n",
    "    o = (concatenate([o, f2], axis=3))\n",
    "    o = (ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING))(o)\n",
    "    o = (Conv2D(64, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n",
    "    o = (BatchNormalization())(o)\n",
    "\n",
    "    o = (UpSampling2D((2, 2), data_format=IMAGE_ORDERING))(o)\n",
    "    o = (concatenate([o, f1], axis=3))\n",
    "    o = (ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING))(o)\n",
    "    o = (Conv2D(32, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n",
    "    o = (BatchNormalization())(o)\n",
    "\n",
    "    o = Conv2D(n_classes, (3, 3), padding='same', data_format=IMAGE_ORDERING)(o)\n",
    "    o= Conv2D(1, 1, activation='sigmoid')(o)\n",
    "    \n",
    "    model = Model(image_input, o)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def load_data():\n",
    "    mydata = dataProcess(512, 512)\n",
    "    imgs_train, imgs_mask_train = mydata.load_train_data()\n",
    "    imgs_test = mydata.load_test_data()\n",
    "    return imgs_train, imgs_mask_train, imgs_test\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = VGG16(2,'vgg16_weights.h5')\n",
    "#     print(model.summary())    \n",
    "    imgs_train, imgs_mask_train, imgs_test=load_data()\n",
    "    model = VGG16(2,'vgg16_weights.h5')\n",
    "    # print(model.summary())\n",
    "    model_checkpoint = ModelCheckpoint('my_VGG_unet.hdf5', monitor='loss', verbose=1, save_best_only=True)\n",
    "    model.compile(optimizer=Adam(lr = 1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(imgs_train, imgs_mask_train, batch_size=4, \n",
    "              nb_epoch=10, verbose=1, validation_split=0.2,\n",
    "              shuffle=True, callbacks=[model_checkpoint,\n",
    "            TensorBoard(log_dir=r\"./mytensotboard_vggunet\", \n",
    "                        update_freq=\"batch\")])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
